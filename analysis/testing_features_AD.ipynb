{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = '/opt/Malware-Project/BigDataset/FEELScenarios/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, 'Processed', 'Client4', 'Day1', \"comb_features_ben.csv\"))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(os.path.join(data_dir, 'Raw', 'Malware', 'CTU-Malware-Capture-Botnet-327-2', 'Day1', \"comb_features.csv\"))\n",
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.SNI_equal_DstIP.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2.self_signed_ratio.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2.ssl_ratio.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].describe()[\"mean\"] == -1 or df[column].describe()[\"mean\"] == 0:\n",
    "        print(column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in df2.columns:\n",
    "    if df2[column].describe()[\"mean\"] == -1:\n",
    "        print(column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Anomaly detection tests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create benign dataset for each day"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = dict()\n",
    "for j in range(1, 6):\n",
    "    data[\"Day\"+str(j)] = pd.DataFrame()\n",
    "    for i in range(1, 11):\n",
    "        df_temp = pd.read_csv(os.path.join(data_dir, 'Processed', 'Client'+str(i), 'Day'+str(j), \"comb_features_ben.csv\"))\n",
    "        data[\"Day\"+str(j)] = pd.concat([data[\"Day\"+str(j)], df_temp], ignore_index=True)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print(f'Size of Day{i} dataframe: {len(data[\"Day\"+str(i)])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    for column in df.columns:\n",
    "        if data[\"Day\"+str(j)][column].describe()[\"mean\"] == -1:\n",
    "            print(i, column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop column \"ssl_ratio\"\n",
    "for i in range(1, 6):\n",
    "    data[\"Day\"+str(i)] = data[\"Day\"+str(i)].drop([\"ssl_ratio\", \"self_signed_ratio\", \"SNI_equal_DstIP\", \"ratio_certificate_path_error\", \"ratio_missing_cert_in_cert_path\"], axis=1)\n",
    "    data[\"Day\"+str(i)] = data[\"Day\"+str(i)].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Final sizes\n",
    "for i in range(1, 6):\n",
    "    print(f'Size of Day{i} dataframe: {len(data[\"Day\"+str(i)])}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create malware dataset (Day1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mal_data = dict()\n",
    "mal_folders = ['CTU-Malware-Capture-Botnet-346-1', 'CTU-Malware-Capture-Botnet-327-2', 'CTU-Malware-Capture-Botnet-230-1', 'CTU-Malware-Capture-Botnet-219-2']\n",
    "\n",
    "for folder in mal_folders:\n",
    "    mal_data[folder] = pd.DataFrame()\n",
    "    df_temp = pd.read_csv(os.path.join(data_dir, 'Raw', 'Malware', folder, 'Day1', \"comb_features.csv\"))\n",
    "    mal_data[folder] = pd.concat([mal_data[folder], df_temp], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    print(f'Size of {folder} dataframe: {len(mal_data[folder])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    for column in df.columns:\n",
    "        if mal_data[folder][column].describe()[\"mean\"] == -1:\n",
    "            print(folder, column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop column \"ssl_ratio\"\n",
    "for folder in mal_folders:\n",
    "    mal_data[folder] = mal_data[folder].drop([\"ssl_ratio\", \"self_signed_ratio\", \"SNI_equal_DstIP\", \"ratio_certificate_path_error\", \"ratio_missing_cert_in_cert_path\"], axis=1)\n",
    "    mal_data[folder] = mal_data[folder].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    print(f'Size of {folder} dataframe: {len(mal_data[folder])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Anomaly detection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Isolation Forests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data[\"Day1\"])\n",
    "scaler = preprocessing.MinMaxScaler().fit(data[\"Day1\"])\n",
    "X = scaler.transform(data[\"Day1\"])\n",
    "iso = IsolationForest(n_estimators=50, \n",
    "                      contamination=0.01,\n",
    "                      random_state=1337).fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = scaler.transform(data[\"Day2\"])\n",
    "print(f'False positives: {100*sum(iso.predict(X_test) == -1) / len(X_test):.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    X_test_mal = scaler.transform(mal_data[folder])\n",
    "    print(f'Detection {folder}: {100*sum(iso.predict(X_test_mal) == -1) / len(X_test_mal):.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LOF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=5, novelty=True, contamination=0.02)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data[\"Day1\"])\n",
    "scaler = preprocessing.MinMaxScaler().fit(data[\"Day1\"])\n",
    "X = scaler.transform(data[\"Day1\"])\n",
    "lof.fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = scaler.transform(data[\"Day2\"])\n",
    "print(f'False positives: {100*sum(lof.predict(X_test) == -1) / len(X_test):.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    X_test_mal = scaler.transform(mal_data[folder])\n",
    "    print(f'Detection {folder}: {100*sum(lof.predict(X_test_mal) == -1) / len(X_test_mal):.2f}% ({sum(lof.predict(X_test_mal)==-1)} out of {len(X_test_mal)})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One class SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.linear_model import SGDOneClassSVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It does better with nu=0.02 but higher FP\n",
    "scaler = preprocessing.MinMaxScaler().fit(data[\"Day1\"])\n",
    "X = scaler.transform(data[\"Day1\"])\n",
    "# svm_ = OneClassSVM(nu=0.02, kernel=\"linear\", gamma=0.1).fit(X)\n",
    "svm_ = SGDOneClassSVM(nu=0.01).fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = scaler.transform(data[\"Day2\"])\n",
    "print(f'False positives: {100*sum(svm_.predict(X_test) == -1) / len(X_test):.2f}% ({sum(svm_.predict(X_test)==-1)} out of {len(X_test)})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in mal_folders:\n",
    "    X_test_mal = scaler.transform(mal_data[folder])\n",
    "    print(f'{folder} detected: {100*sum(svm_.predict(X_test_mal) == -1) / len(X_test_mal):.2f}% ({sum(svm_.predict(X_test_mal)==-1)} out of {len(X_test_mal)})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autoencoders (NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Input(shape=(36)),\n",
    "        tf.keras.layers.Dense(32, activation='elu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(20, activation='elu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(10, activation='elu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(20, activation='elu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(32, activation='elu'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(36, activation='elu')\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 8\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(data[\"Day4\"])\n",
    "X_test = scaler.transform(data[\"Day5\"])\n",
    "\n",
    "X_train , X_val = train_test_split(X, test_size=0.2, random_state=8181)\n",
    "\n",
    "# X = data[\"Day1\"]\n",
    "# X_test = data[\"Day2\"]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, X_train,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "#     callbacks=cb,\n",
    "    validation_data=(X_val, X_val)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val loss\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rec_ben = model.predict(X_test)\n",
    "mse_ben = np.mean(np.power(X_test - rec_ben, 2), axis=1)\n",
    "\n",
    "\n",
    "rec_mal = dict()\n",
    "mse_mal = dict()\n",
    "num_malware = 0\n",
    "for folder in mal_folders:\n",
    "    X_test_mal = scaler.transform(mal_data[folder])\n",
    "    num_malware += X_test_mal.shape[0]\n",
    "    rec_mal[folder] = model.predict(X_test_mal)\n",
    "    mse_mal[folder] = np.mean(np.power(X_test_mal - rec_mal[folder], 2), axis=1)\n",
    "\n",
    "num_malware"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "# ax.hist(mse_ben, bins=10, density=False, label=\"clean\", alpha=.6, color=\"green\")\n",
    "# for folder in mal_folders:\n",
    "# ax.hist(mse_mal[\"CTU-Malware-Capture-Botnet-346-1\"], bins=10, density=False, label=\"CTU-Malware-Capture-Botnet-346-1\", alpha=.6)\n",
    "# ax.hist(mse_mal[\"CTU-Malware-Capture-Botnet-327-2\"], bins=10, density=False, label=\"CTU-Malware-Capture-Botnet-327-2\", alpha=.6)\n",
    "# ax.hist(mse_mal[\"CTU-Malware-Capture-Botnet-230-1\"], bins=10, density=False, label=\"CTU-Malware-Capture-Botnet-230-1\", alpha=.6)\n",
    "ax.hist(mse_mal[\"CTU-Malware-Capture-Botnet-219-2\"], bins=10, density=False, label=\"CTU-Malware-Capture-Botnet-219-2\", alpha=.6)\n",
    "\n",
    "\n",
    "plt.title(\"Distribution of the Reconstruction Loss\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The number of faulty samples for a 2% FPR (on the training set)\n",
    "rec_ben = model.predict(X_val)\n",
    "mse_ben = np.mean(np.power(X_val - rec_ben, 2), axis=1)\n",
    "\n",
    "num = 0.01*len(X_val)\n",
    "\n",
    "th = 0.001\n",
    "while (sum(mse_ben > th) > num):\n",
    "    th += 0.001\n",
    "print(f\"Calculated threshold: {th:.5f}\")\n",
    "\n",
    "# Measure in the testset\n",
    "rec_ben = model.predict(X_test)\n",
    "mse_ben = np.mean(np.power(X_test - rec_ben, 2), axis=1)\n",
    "print(f'False positives on next day: { 100*sum(mse_ben > th) / len(X_test):.2f}% ({sum(mse_ben > th)} out of {len(X_test)})')\n",
    "anomalies_ben = sum(mse_ben > th)\n",
    "num_examples_test = X_test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomalies_mal = 0\n",
    "for folder in mal_folders:\n",
    "    anomalies_mal += sum(mse_mal[folder] > th)\n",
    "    print(f'{folder} detected: {100*sum(mse_mal[folder] > th) / len(mse_mal[folder]):.2f}% ({sum(mse_mal[folder] > th)} out of {len(mse_mal[folder])})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fp = anomalies_ben\n",
    "tp = anomalies_mal\n",
    "tn = num_examples_test - fp\n",
    "fn = num_malware - tp\n",
    "\n",
    "accuracy = (tp + tn) / (num_examples_test + num_malware)\n",
    "tpr = tp / num_malware\n",
    "fpr = fp / num_examples_test\n",
    "\n",
    "# Metrics on the test set for both malware and benign data\n",
    "print(f\"Centralized accuracy: {100*accuracy:.2f}%\")\n",
    "print(f\"Centralized tpr: {100*tpr:.2f}%\")\n",
    "print(f\"Centralized fpr: {100*fpr:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "36c92f7767776a2827c74549f7a5f711a4ca8d6f93bcffb5a92ce2d4e492ca7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}